{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:53:35.012189Z",
     "iopub.status.busy": "2025-03-25T14:53:35.011800Z",
     "iopub.status.idle": "2025-03-25T14:53:49.317697Z",
     "shell.execute_reply": "2025-03-25T14:53:49.316877Z",
     "shell.execute_reply.started": "2025-03-25T14:53:35.012128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import unets as un\n",
    "import tf_utils as tfu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:54:03.010132Z",
     "iopub.status.busy": "2025-03-25T14:54:03.009769Z",
     "iopub.status.idle": "2025-03-25T14:54:09.162434Z",
     "shell.execute_reply": "2025-03-25T14:54:09.161649Z",
     "shell.execute_reply.started": "2025-03-25T14:54:03.010102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "unet = un.UNet4(input_size=(256, 256, 3), num_classes=1)\n",
    "\n",
    "# Call the model with a random input to build the model\n",
    "out = unet.call(tf.random.normal((1, 256, 256, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load only weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "unet = un.UNet4cSE(input_size=(256, 256, 3), num_classes=1)\n",
    "\n",
    "# Call the model with a random input to build the model\n",
    "out = unet.call(tf.random.normal((1, 256, 256, 3)))\n",
    "\n",
    "unet.build((1, 256, 256, 3))\n",
    "\n",
    "# Restore the weights\n",
    "unet.load_weights(\"Models//unet_cse_aug_4.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (16, 256, 256, 3)\n",
      "Mask batch shape: (16, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Set the directory paths\n",
    "test_image_folder = 'ISIC-Merged\\\\test_images'\n",
    "test_mask_folder = 'ISIC-Merged\\\\test_masks'\n",
    "\n",
    "# Load the dataset\n",
    "test_dataset = tfu.load_data(test_image_folder, test_mask_folder)\n",
    "\n",
    "# Check the dataset shapes (optional)\n",
    "for images, masks in test_dataset.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Mask batch shape:\", masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tfu.bce_dice_loss, metrics=[tfu.jaccard_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = unet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_images_dir = '/kaggle/input/isic-2016-2017/split/test_images'\n",
    "test_masks_dir = '/kaggle/input/isic-2016-2017/split/test_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get sorted image filenames (only images, not masks)\n",
    "image_filenames = sorted([f for f in os.listdir(test_images_dir) if f.endswith(\".jpg\")])\n",
    "\n",
    "# Iterate Over Images and Select Corresponding Mask\n",
    "image_list = []\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for img_filename in image_filenames:\n",
    "    img_path = os.path.join(test_images_dir, img_filename)\n",
    "\n",
    "    # Construct the corresponding mask filename\n",
    "    mask_filename = img_filename.replace(\".jpg\", \"_segmentation.png\")\n",
    "    mask_path = os.path.join(test_masks_dir, mask_filename)\n",
    "\n",
    "    # Load image and mask using your existing functions\n",
    "    image_np = load_image(img_path).numpy()\n",
    "    mask_tensor = load_mask(mask_path)  # Full mask path is passed correctly\n",
    "\n",
    "    if mask_tensor is None:\n",
    "        print(f\" Skipping: No mask found for {img_filename}\")\n",
    "        continue  # Skip this image if the mask is missing\n",
    "\n",
    "    mask_np = mask_tensor.numpy()\n",
    "\n",
    "    # Get model prediction\n",
    "    predicted_mask = unet.predict(np.expand_dims(image_np, axis=0), verbose=0)  # Add batch dimension\n",
    "\n",
    "    # Threshold prediction to binary mask\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Store correctly paired results\n",
    "    image_list.append(image_np)\n",
    "    y_true_list.append(mask_np)\n",
    "    y_pred_list.append(predicted_mask.squeeze())  # Remove batch dimension\n",
    "\n",
    "# Convert Lists to Arrays\n",
    "image_data = np.array(image_list)  # Shape: (N, 256, 256, 3)\n",
    "y_true = np.array(y_true_list)  # Shape: (N, 256, 256, 1)\n",
    "y_pred = np.array(y_pred_list)  # Shape: (N, 256, 256, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize First Image-Mask-Prediction Pairs\n",
    "num_images_to_show = 20\n",
    "fig, axes = plt.subplots(num_images_to_show, 3, figsize=(20, 20))\n",
    "\n",
    "for i in range(num_images_to_show):\n",
    "    axes[i, 0].imshow(image_data[i])\n",
    "    axes[i, 0].set_title(\"Original Image\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    axes[i, 1].imshow(np.squeeze(y_true[i]), cmap=\"gray\")\n",
    "    axes[i, 1].set_title(\"Ground Truth Mask\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "    axes[i, 2].imshow(np.squeeze(y_pred[i]), cmap=\"gray\")\n",
    "    axes[i, 2].set_title(\"Predicted Mask\")\n",
    "    axes[i, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "custom_images_dir = '/kaggle/input/my-skin-lesions/my_normalized_skin_lesions'\n",
    "\n",
    "# Get sorted image filenames (only images, not masks)\n",
    "image_filenames = sorted([f for f in os.listdir(custom_images_dir) if f.endswith(\".jpg\")])\n",
    "\n",
    "# Iterate Over Images and Select Corresponding Mask\n",
    "image_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for img_filename in image_filenames:\n",
    "    img_path = os.path.join(custom_images_dir, img_filename)\n",
    "\n",
    "    # Load image and mask using your existing functions\n",
    "    image_np = load_image(img_path).numpy()\n",
    "\n",
    "    # Get model prediction\n",
    "    predicted_mask = unet.predict(np.expand_dims(image_np, axis=0))  # Add batch dimension\n",
    "\n",
    "    # Threshold prediction to binary mask\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Store correctly paired results\n",
    "    image_list.append(image_np)\n",
    "    y_pred_list.append(predicted_mask.squeeze())  # Remove batch dimension\n",
    "\n",
    "# Convert Lists to Arrays\n",
    "image_data = np.array(image_list)  # Shape: (N, 256, 256, 3)\n",
    "y_pred = np.array(y_pred_list)  # Shape: (N, 256, 256, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize First Image-Mask-Prediction Pairs\n",
    "num_images_to_show = 3\n",
    "fig, axes = plt.subplots(num_images_to_show, 2, figsize=(5, 5))\n",
    "\n",
    "for i in range(num_images_to_show):\n",
    "    axes[i, 0].imshow(image_data[i])\n",
    "    axes[i, 0].set_title(\"Original Image\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    axes[i, 1].imshow(np.squeeze(y_pred[i]), cmap=\"gray\")\n",
    "    axes[i, 1].set_title(\"Predicted Mask\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6738063,
     "sourceId": 10849646,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6774271,
     "sourceId": 10928636,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6803307,
     "sourceId": 11151029,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 277566,
     "modelInstanceId": 256248,
     "sourceId": 299934,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 277585,
     "modelInstanceId": 256268,
     "sourceId": 299966,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
